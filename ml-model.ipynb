{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a13ada-511b-4c45-a412-d8ecd86824e7",
   "metadata": {},
   "source": [
    "# Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5db48-9bb1-4c31-b57a-3e68355cf4ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %conda install -c conda-forge awswrangler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ee9be-3f09-431d-9e06-dd91f4b0934b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd0106b4-47c9-4391-893d-ccb99cf13fd9",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-14T22:46:46.482811300Z",
     "start_time": "2023-12-14T22:46:37.725615900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import boto3\n",
    "import awswrangler as wr\n",
    "import warnings\n",
    "from textblob import TextBlob\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a501f3-6a95-4087-bab1-ba5df30a2b71",
   "metadata": {},
   "source": [
    "### Reading Processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "session = boto3.Session(\n",
    "    aws_access_key_id='AKIAUOGQLRFI3ZXAF6MR',\n",
    "    aws_secret_access_key='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',\n",
    ")\n",
    "s3 = session.resource('s3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T19:12:47.300914600Z",
     "start_time": "2023-12-14T19:12:47.139179700Z"
    }
   },
   "id": "d4bf9b0331adc7d9"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defcaa66-b5ce-4ea5-bf96-f2b7a54d8b5b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-14T19:20:18.790503300Z",
     "start_time": "2023-12-14T19:12:48.145169200Z"
    }
   },
   "outputs": [],
   "source": [
    "source_uris = ['s3://comp333-data/processed_data/combined/run-1702446295691-part-r-00000.gz', \n",
    "              's3://comp333-data/processed_data/combined/run-1702446295691-part-r-00001.gz', \n",
    "              's3://comp333-data/processed_data/combined/run-1702446295691-part-r-00002.gz']\n",
    "dfs = wr.s3.read_json(path=source_uris, chunksize=1000, lines=True)\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc6744a1-c50f-4c3f-aea1-74cbb0c7d025",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-14T19:21:21.821093800Z",
     "start_time": "2023-12-14T19:21:21.809117300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            review_time                                        review_text  \\\n",
      "0   2023-02-13 22:53:30  Ok so I want to preface this with... This laun...   \n",
      "1   2022-11-11 02:45:39  4 years in EA and the game is still a buggy me...   \n",
      "2   2023-08-18 00:01:44  Mimimi has struck gold again with Shadow Gambi...   \n",
      "3   2023-08-18 14:25:37  In short: Valheim with zombies and guns. In mo...   \n",
      "4   2023-07-22 15:53:27  This is one of those titles that proves you do...   \n",
      "..                  ...                                                ...   \n",
      "95  2023-06-09 05:56:59           i'm so glad i gave these people my money   \n",
      "96  2023-07-25 04:51:01  Really nice Sim Survival game! Still need some...   \n",
      "97  2023-08-01 20:40:51  Finally a sequel to the previous game. I have ...   \n",
      "98  2020-11-28 15:01:29                                        Nice gane\\n   \n",
      "99  2023-11-13 04:25:24  I'm having fun, and continue to enjoy it despi...   \n",
      "\n",
      "    review_id recommended  hours_played        review_user  app_title  \n",
      "0   132800638       false            -1  76561198085609216        NaN  \n",
      "1   125276587       false            -1  76561198032738496        NaN  \n",
      "2   144449054       false            -1  76561198009420800        NaN  \n",
      "3   144490526       false            -1  76561198073167248        NaN  \n",
      "4   142590844       false            -1  76561198002674592        NaN  \n",
      "..        ...         ...           ...                ...        ...  \n",
      "95  139769141       false            -1  76561198415119488        NaN  \n",
      "96  142742353       false            -1  76561198004927616        NaN  \n",
      "97  143224399       false            -1  76561197991973568        NaN  \n",
      "98   80876743       false            -1  76561198054321856        NaN  \n",
      "99  150044968       false            -1  76561198038289536        NaN  \n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c0e81-be73-4c68-b06b-ae4b48fd175a",
   "metadata": {},
   "source": [
    "### Sentiment score from user review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f58646b-b9a2-4d99-8a09-bde5560a59a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T22:47:36.485101300Z",
     "start_time": "2023-12-14T22:47:36.475929900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get normalized sentiment score using TextBlob\n",
    "def get_sentiment_score(text):\n",
    "    analysis = TextBlob(text)\n",
    "    # Normalize sentiment score to be in the range of -1 to 1\n",
    "    return analysis.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Convert data to its appropriate types\n",
    "df['review_text'] = df['review_text'].astype(str)\n",
    "df['recommended'] = df['recommended'].astype(int)\n",
    "df['review_user'] = df['review_user'].astype(str)\n",
    "df['app_title'] = df['app_title'].astype(str)\n",
    "\n",
    "# Apply sentiment analysis and create a new column 'sentiment_score'\n",
    "df['sentiment_score'] = df['review_text'].apply(get_sentiment_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T22:55:09.252554300Z",
     "start_time": "2023-12-14T22:54:25.106653600Z"
    }
   },
   "id": "cfcb01517ef14f6a"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(input_size, hidden_sizes[0], )\n",
    "        self.layer2 = torch.nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.layer3 = torch.nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
    "        self.layer4 = torch.nn.Linear(hidden_sizes[2], hidden_sizes[3])\n",
    "        self.layer5 = torch.nn.Linear(hidden_sizes[3], output_size)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T23:25:16.598219900Z",
     "start_time": "2023-12-14T23:25:16.560668400Z"
    }
   },
   "id": "c9546470a857e5ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "train = df.sample(frac=0.8, random_state=200)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=256)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=256)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef442a66d113be1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define input, hidden, and output sizes\n",
    "input_size = df.shape[1] - 1\n",
    "hidden_size = [100, 50, 25, 10]\n",
    "output_size = 1\n",
    "\n",
    "# Initialize the model\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000\n",
    "weight_decay = 0.0001\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18ba88b099f7039e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the model\n",
    "loss = 0\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, row in enumerate(train_loader):\n",
    "        # Get data\n",
    "        inputs = row.drop(['recommended'], axis=1).to_numpy()\n",
    "        labels = row['recommended'].to_numpy()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Save loss\n",
    "    losses.append(loss.item())\n",
    "        \n",
    "    # Print loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch: {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "print(f'Finished training | Loss: {loss.item():.4f}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1381b437189bd2c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
